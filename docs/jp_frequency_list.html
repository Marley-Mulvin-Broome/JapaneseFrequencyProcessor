<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>jpfreq.jp_frequency_list API documentation</title>
<meta name="description" content="Japanese Frequency List …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>jpfreq.jp_frequency_list</code></h1>
</header>
<section id="section-intro">
<h1 id="japanese-frequency-list">Japanese Frequency List</h1>
<p>This module contains the main class <code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList">JapaneseFrequencyList</a></code>, which will be the main thing you are going to be working with.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
.. include:: ../../documentation/jp_frequency_list.md
&#34;&#34;&#34;

from fugashi import Tagger
from typing import Callable
from os.path import isfile as file_exists

from .word_slot import WordSlot, get_unique_wordslots
from .text_info import TextInfo
from .kanji import all_kanji_in_string, Kanji
from .util import percent_of
from .word import Word, WordType

EXCLUDED_WORD_TYPES: list[WordType] = [
    WordType.PARTICLE,
    WordType.AUXILIARY_VERB,
    WordType.SUPPLEMENTARY_SYMBOL,
    WordType.BLANK_SPACE,
    WordType.NUMERAL,
]


def word_validator_exclude_by_type(input_word: Word, excluded_word_types=None) -&gt; bool:
    &#34;&#34;&#34;
    Validates a word by excluding it if it is of a certain type lists in `excluded_word_types`.

    Parameters
    ----------
    input_word : UnidicNode
        The word to validate.
    excluded_word_types : list[str]
        A list of word types to exclude. Defaults to `EXCLUDED_WORD_TYPES`.

    Returns
    -------
    bool
        Whether the word is valid or not.
    &#34;&#34;&#34;
    if excluded_word_types is None:
        excluded_word_types = EXCLUDED_WORD_TYPES
    for word_type in input_word.types:
        if word_type in excluded_word_types:
            return False

    return True


class JapaneseFrequencyList:
    &#34;&#34;&#34;
    A class for storing the frequency of words in a Japanese text.
    &#34;&#34;&#34;

    _unique_words: dict[str, WordSlot]
    _unique_kanji: dict[str, Kanji]
    _word_count: int
    _tagger: Tagger
    _word_validator: Callable[[Word], bool]

    def __init__(
        self,
        word_validator: Callable[[Word], bool] = word_validator_exclude_by_type,
        text_to_analyse: list = None,
        tagger_instance=None,
    ):
        self._unique_words = {}
        self._unique_kanji = {}
        self._word_count = 0

        self._word_validator = word_validator

        self._tagger = tagger_instance
        if not self._tagger:
            self._tagger = Tagger(&#34;-Owakati&#34;)
        elif not isinstance(self._tagger, Tagger):
            raise TypeError(
                f&#34;JapaneseFrequencyList: tagger_instance must be of type fugashi.Tagger, not {type(self._tagger)}&#34;
            )

        if text_to_analyse is not None:
            self.process_texts(text_to_analyse)

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;
        The number of unique words in the frequency list.
        Returns
        -------
        int
            The number of unique words in the frequency list.
        &#34;&#34;&#34;
        return len(self.wordslots)

    def __repr__(self) -&gt; str:  # pragma: no cover
        &#34;&#34;&#34;
        A string representation of the frequency list in the form: &#39;JapaneseFrequencyList(text_info=TextInfo(...))&#39;
        Returns
        -------

        &#34;&#34;&#34;
        text_info = self.generate_text_info()
        return f&#34;JapaneseFrequencyList(\ntext_info={text_info!r}\n)&#34;

    def __contains__(self, word: str) -&gt; bool:
        &#34;&#34;&#34;
        Whether the representation of a word is in the frequency list.
        Parameters
        ----------
        word : str
            The word to check for.

        Returns
        -------
        bool
            Whether the word is in the frequency list.
        &#34;&#34;&#34;
        return word in self._unique_words.keys()

    def __getitem__(self, word: str) -&gt; WordSlot:
        &#34;&#34;&#34;
        Returns the WordSlot for the specified word.
        This will search using the word&#39;s representation, not its surface.
        This means that if you pass &#34;これ&#34;, it will fail, as the representation is &#34;此れ&#34;.
        Please see the function `get_representation` in this class to get the representation of a word.
        Parameters
        ----------
        word

        Returns
        -------

        &#34;&#34;&#34;
        if word not in self._unique_words.keys():
            raise KeyError(f&#34;Word &#39;{word}&#39; not found in frequency list&#34;)

        return self._unique_words[word]

    @property
    def wordslots(self) -&gt; list[WordSlot]:
        &#34;&#34;&#34;
        Returns a list of all the wordslots.
        Returns
        -------
        list[WordSlot]
            A list of all the wordslots.
        &#34;&#34;&#34;
        return list(self._unique_words.values())

    @property
    def word_count(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of words.
        Returns
        -------
        int
            The number of words.
        &#34;&#34;&#34;
        return self._word_count

    @property
    def unique_words(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of unique words.
        Returns
        -------
        int
            The number of unique words.
        &#34;&#34;&#34;
        return len(self.wordslots)

    @property
    def unique_words_used_once(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of unique words used once.
        Returns
        -------
        int
            The number of unique words used once.
        &#34;&#34;&#34;
        return len(get_unique_wordslots(self.wordslots))

    @property
    def unique_words_all(self) -&gt; tuple[int, int, float]:
        &#34;&#34;&#34;
        Returns the number of unique words, the number of unique words used once, and the percentage of unique words used once.
        Returns
        -------
        tuple[int, int, float]
            unique_words, unique_words_used_once, unique_words_used_once_percentage
        &#34;&#34;&#34;
        unique_words: int = self.unique_words
        unique_words_used_once: int = self.unique_words_used_once

        unique_word_percentage: float = percent_of(unique_words_used_once, unique_words)

        return unique_words, unique_words_used_once, unique_word_percentage

    @property
    def unique_kanji(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of unique kanji.
        Returns
        -------
        int
            The number of unique kanji.
        &#34;&#34;&#34;
        return len(self._unique_kanji)

    @property
    def unique_kanji_used_once(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of unique kanji used once.
        Returns
        -------
        int
            The number of unique kanji used once.
        &#34;&#34;&#34;
        return len(
            [kanji for kanji in self._unique_kanji.values() if kanji.frequency == 1]
        )

    @property
    def unique_kanji_all(self) -&gt; tuple[int, int, float]:
        &#34;&#34;&#34;
        Returns the number of unique kanji, the number of unique kanji used once, and the percentage of unique kanji used once.
        Returns
        -------
        tuple[int, int, float]
            unique_kanji, unique_kanji_used_once, unique_kanji_used_once_percentage
        &#34;&#34;&#34;
        unique_kanji: int = self.unique_kanji
        unique_kanji_used_once: int = self.unique_kanji_used_once

        unique_kanji_percentage: float = percent_of(
            unique_kanji_used_once, unique_kanji
        )

        return unique_kanji, unique_kanji_used_once, unique_kanji_percentage

    def clear(self) -&gt; None:
        &#34;&#34;&#34;
        Clears the frequency list of all words and kanji, reverting it to its initial state.
        &#34;&#34;&#34;
        self._word_count = 0

        self._unique_words.clear()
        self._unique_kanji.clear()

    def get_most_frequent(self, limit: int = 100) -&gt; list[WordSlot]:
        &#34;&#34;&#34;
        Returns a list of the most frequent words in the text with the specified limit.
        If limit is -1, then all words are returned.
        Parameters
        ----------
        limit : int
            The number of words to return.
        Returns
        -------
        list[WordSlot]
            A list of the most frequent words in the text with the specified limit, sorted by frequency.
        &#34;&#34;&#34;
        item_array: list[WordSlot] = sorted(
            self.wordslots, key=lambda x: x.frequency, reverse=True
        )

        if limit == -1 or limit &gt; len(item_array):
            return item_array

        return item_array[:limit]

    def generate_text_info(self) -&gt; TextInfo:
        &#34;&#34;&#34;
        Generates a TextInfo object from the frequency list.
        Returns
        -------
        TextInfo
            A TextInfo object containing information about the text.
        &#34;&#34;&#34;
        (
            unique_words,
            unique_words_used_once,
            unique_word_percentage,
        ) = self.unique_words_all
        (
            unique_kanji,
            unique_kanji_used_once,
            unique_kanji_percentage,
        ) = self.unique_kanji_all

        return TextInfo(
            self.word_count,
            unique_words,
            unique_words_used_once,
            unique_word_percentage,
            unique_kanji,
            unique_kanji_used_once,
            unique_kanji_percentage,
        )

    def add_kanji(self, kanji: Kanji) -&gt; None:
        &#34;&#34;&#34;
        Adds a kanji to the frequency list.
        Parameters
        ----------
        kanji : Kanji
            The kanji to add.
        &#34;&#34;&#34;
        if kanji.representation in self._unique_kanji:
            self._unique_kanji[kanji.representation].frequency += 1
            return

        self._unique_kanji[kanji.representation] = kanji

    def add_word(self, word: Word) -&gt; None:
        &#34;&#34;&#34;
        Adds a word to the frequency list.

        If the word is already in the list, then the frequency is increased by 1.
        Otherwise, the word is added to the list with a frequency of 1.

        Note: This method assumes the word is valid.

        Parameters
        ----------
        word : Word
            The word to add.
        &#34;&#34;&#34;
        self._word_count += 1

        if word.representation in self._unique_words.keys():
            self._unique_words[word.representation].add_word(word)
            return

        # if there is no representation of this word then we must add one
        self._unique_words[word.representation] = WordSlot([word])

    def get_representation(self, word: str) -&gt; str:
        &#34;&#34;&#34;
        Returns the representation of a word.
        This is the word without any inflections.
        For example, the representation of &#34;これ&#34; is &#34;此れ&#34;.
        The representation of &#34;行った&#34; is &#34;行く&#34;.
        Parameters
        ----------
        word : str
            The word to get the representation of.
        Returns
        -------
        str
            The representation of the word.
        &#34;&#34;&#34;
        processed_word = self.parse_line(word)[0]

        if len(processed_word) &lt; 1:
            raise ValueError(f&#34;Word &#39;{word}&#39; is not a valid word&#34;)

        return processed_word[0].representation

    def parse_line(self, line: str) -&gt; tuple[list[Word], list[Kanji]]:
        &#34;&#34;&#34;
        Parses a line of text into a list of Words and a list of Kanji.
        Backbone of all parsing.

        Parameters
        ----------
        line : str
            The line to parse.

        Returns
        -------
        tuple[list[Word], list[Kanji]]
            A tuple containing the list of Words and the list of Kanji.
        &#34;&#34;&#34;
        words = self._tagger(line)

        return [Word.from_node(word) for word in words], all_kanji_in_string(line)

    def process_line(self, line_to_process: str) -&gt; None:
        &#34;&#34;&#34;
        Parses a line, adding the valid words and all kanji to the frequency list.
        All other processing functions boil down to this.

        Parameters
        ----------
        line_to_process : str
            The line to process.
        &#34;&#34;&#34;
        line_to_process = line_to_process.replace(&#34;\n&#34;, &#34;&#34;)
        words, kanji = self.parse_line(line_to_process)

        [self.add_kanji(kanji) for kanji in kanji]
        [self.add_word(word) for word in words if self._word_validator(word)]

    def process_text(self, text_to_process: str) -&gt; None:
        &#34;&#34;&#34;
        Parses a string split by the newline character, adding the valid words to the frequency list.

        Parameters
        ----------
        text_to_process : str
            Text potentially containing multiple lines.
        &#34;&#34;&#34;
        [self.process_line(line) for line in text_to_process.split(&#34;\n&#34;)]

    def process_texts(self, texts_to_process: list) -&gt; None:
        &#34;&#34;&#34;
        Parses a list of texts, adding the valid words to the frequency list.

        Parameters
        ----------
        texts_to_process : list
            A list of texts to process.
        &#34;&#34;&#34;
        [self.process_text(text) for text in texts_to_process]

    def process_file(self, file_path: str) -&gt; None:
        &#34;&#34;&#34;
        Parses a file, adding the valid words to the frequency list.
        Parameters
        ----------
        file_path : str
            The path to the file to process.
        &#34;&#34;&#34;
        if not file_exists(file_path):
            raise FileExistsError(
                f&#34;process_file: File path passed doesn&#39;t exist ({file_path})&#34;
            )

        with open(file_path, &#34;r&#34;, encoding=&#34;utf-8&#34;) as fs:
            [self.process_line(line) for line in fs]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="jpfreq.jp_frequency_list.word_validator_exclude_by_type"><code class="name flex">
<span>def <span class="ident">word_validator_exclude_by_type</span></span>(<span>input_word: <a title="jpfreq.word.Word" href="word.html#jpfreq.word.Word">Word</a>, excluded_word_types=None) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Validates a word by excluding it if it is of a certain type lists in <code>excluded_word_types</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>input_word</code></strong> :&ensp;<code>UnidicNode</code></dt>
<dd>The word to validate.</dd>
<dt><strong><code>excluded_word_types</code></strong> :&ensp;<code>list[str]</code></dt>
<dd>A list of word types to exclude. Defaults to <code>EXCLUDED_WORD_TYPES</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Whether the word is valid or not.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def word_validator_exclude_by_type(input_word: Word, excluded_word_types=None) -&gt; bool:
    &#34;&#34;&#34;
    Validates a word by excluding it if it is of a certain type lists in `excluded_word_types`.

    Parameters
    ----------
    input_word : UnidicNode
        The word to validate.
    excluded_word_types : list[str]
        A list of word types to exclude. Defaults to `EXCLUDED_WORD_TYPES`.

    Returns
    -------
    bool
        Whether the word is valid or not.
    &#34;&#34;&#34;
    if excluded_word_types is None:
        excluded_word_types = EXCLUDED_WORD_TYPES
    for word_type in input_word.types:
        if word_type in excluded_word_types:
            return False

    return True</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList"><code class="flex name class">
<span>class <span class="ident">JapaneseFrequencyList</span></span>
<span>(</span><span>word_validator: Callable[[<a title="jpfreq.word.Word" href="word.html#jpfreq.word.Word">Word</a>], bool] = &lt;function word_validator_exclude_by_type&gt;, text_to_analyse: list = None, tagger_instance=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A class for storing the frequency of words in a Japanese text.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class JapaneseFrequencyList:
    &#34;&#34;&#34;
    A class for storing the frequency of words in a Japanese text.
    &#34;&#34;&#34;

    _unique_words: dict[str, WordSlot]
    _unique_kanji: dict[str, Kanji]
    _word_count: int
    _tagger: Tagger
    _word_validator: Callable[[Word], bool]

    def __init__(
        self,
        word_validator: Callable[[Word], bool] = word_validator_exclude_by_type,
        text_to_analyse: list = None,
        tagger_instance=None,
    ):
        self._unique_words = {}
        self._unique_kanji = {}
        self._word_count = 0

        self._word_validator = word_validator

        self._tagger = tagger_instance
        if not self._tagger:
            self._tagger = Tagger(&#34;-Owakati&#34;)
        elif not isinstance(self._tagger, Tagger):
            raise TypeError(
                f&#34;JapaneseFrequencyList: tagger_instance must be of type fugashi.Tagger, not {type(self._tagger)}&#34;
            )

        if text_to_analyse is not None:
            self.process_texts(text_to_analyse)

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;
        The number of unique words in the frequency list.
        Returns
        -------
        int
            The number of unique words in the frequency list.
        &#34;&#34;&#34;
        return len(self.wordslots)

    def __repr__(self) -&gt; str:  # pragma: no cover
        &#34;&#34;&#34;
        A string representation of the frequency list in the form: &#39;JapaneseFrequencyList(text_info=TextInfo(...))&#39;
        Returns
        -------

        &#34;&#34;&#34;
        text_info = self.generate_text_info()
        return f&#34;JapaneseFrequencyList(\ntext_info={text_info!r}\n)&#34;

    def __contains__(self, word: str) -&gt; bool:
        &#34;&#34;&#34;
        Whether the representation of a word is in the frequency list.
        Parameters
        ----------
        word : str
            The word to check for.

        Returns
        -------
        bool
            Whether the word is in the frequency list.
        &#34;&#34;&#34;
        return word in self._unique_words.keys()

    def __getitem__(self, word: str) -&gt; WordSlot:
        &#34;&#34;&#34;
        Returns the WordSlot for the specified word.
        This will search using the word&#39;s representation, not its surface.
        This means that if you pass &#34;これ&#34;, it will fail, as the representation is &#34;此れ&#34;.
        Please see the function `get_representation` in this class to get the representation of a word.
        Parameters
        ----------
        word

        Returns
        -------

        &#34;&#34;&#34;
        if word not in self._unique_words.keys():
            raise KeyError(f&#34;Word &#39;{word}&#39; not found in frequency list&#34;)

        return self._unique_words[word]

    @property
    def wordslots(self) -&gt; list[WordSlot]:
        &#34;&#34;&#34;
        Returns a list of all the wordslots.
        Returns
        -------
        list[WordSlot]
            A list of all the wordslots.
        &#34;&#34;&#34;
        return list(self._unique_words.values())

    @property
    def word_count(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of words.
        Returns
        -------
        int
            The number of words.
        &#34;&#34;&#34;
        return self._word_count

    @property
    def unique_words(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of unique words.
        Returns
        -------
        int
            The number of unique words.
        &#34;&#34;&#34;
        return len(self.wordslots)

    @property
    def unique_words_used_once(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of unique words used once.
        Returns
        -------
        int
            The number of unique words used once.
        &#34;&#34;&#34;
        return len(get_unique_wordslots(self.wordslots))

    @property
    def unique_words_all(self) -&gt; tuple[int, int, float]:
        &#34;&#34;&#34;
        Returns the number of unique words, the number of unique words used once, and the percentage of unique words used once.
        Returns
        -------
        tuple[int, int, float]
            unique_words, unique_words_used_once, unique_words_used_once_percentage
        &#34;&#34;&#34;
        unique_words: int = self.unique_words
        unique_words_used_once: int = self.unique_words_used_once

        unique_word_percentage: float = percent_of(unique_words_used_once, unique_words)

        return unique_words, unique_words_used_once, unique_word_percentage

    @property
    def unique_kanji(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of unique kanji.
        Returns
        -------
        int
            The number of unique kanji.
        &#34;&#34;&#34;
        return len(self._unique_kanji)

    @property
    def unique_kanji_used_once(self) -&gt; int:
        &#34;&#34;&#34;
        Returns the number of unique kanji used once.
        Returns
        -------
        int
            The number of unique kanji used once.
        &#34;&#34;&#34;
        return len(
            [kanji for kanji in self._unique_kanji.values() if kanji.frequency == 1]
        )

    @property
    def unique_kanji_all(self) -&gt; tuple[int, int, float]:
        &#34;&#34;&#34;
        Returns the number of unique kanji, the number of unique kanji used once, and the percentage of unique kanji used once.
        Returns
        -------
        tuple[int, int, float]
            unique_kanji, unique_kanji_used_once, unique_kanji_used_once_percentage
        &#34;&#34;&#34;
        unique_kanji: int = self.unique_kanji
        unique_kanji_used_once: int = self.unique_kanji_used_once

        unique_kanji_percentage: float = percent_of(
            unique_kanji_used_once, unique_kanji
        )

        return unique_kanji, unique_kanji_used_once, unique_kanji_percentage

    def clear(self) -&gt; None:
        &#34;&#34;&#34;
        Clears the frequency list of all words and kanji, reverting it to its initial state.
        &#34;&#34;&#34;
        self._word_count = 0

        self._unique_words.clear()
        self._unique_kanji.clear()

    def get_most_frequent(self, limit: int = 100) -&gt; list[WordSlot]:
        &#34;&#34;&#34;
        Returns a list of the most frequent words in the text with the specified limit.
        If limit is -1, then all words are returned.
        Parameters
        ----------
        limit : int
            The number of words to return.
        Returns
        -------
        list[WordSlot]
            A list of the most frequent words in the text with the specified limit, sorted by frequency.
        &#34;&#34;&#34;
        item_array: list[WordSlot] = sorted(
            self.wordslots, key=lambda x: x.frequency, reverse=True
        )

        if limit == -1 or limit &gt; len(item_array):
            return item_array

        return item_array[:limit]

    def generate_text_info(self) -&gt; TextInfo:
        &#34;&#34;&#34;
        Generates a TextInfo object from the frequency list.
        Returns
        -------
        TextInfo
            A TextInfo object containing information about the text.
        &#34;&#34;&#34;
        (
            unique_words,
            unique_words_used_once,
            unique_word_percentage,
        ) = self.unique_words_all
        (
            unique_kanji,
            unique_kanji_used_once,
            unique_kanji_percentage,
        ) = self.unique_kanji_all

        return TextInfo(
            self.word_count,
            unique_words,
            unique_words_used_once,
            unique_word_percentage,
            unique_kanji,
            unique_kanji_used_once,
            unique_kanji_percentage,
        )

    def add_kanji(self, kanji: Kanji) -&gt; None:
        &#34;&#34;&#34;
        Adds a kanji to the frequency list.
        Parameters
        ----------
        kanji : Kanji
            The kanji to add.
        &#34;&#34;&#34;
        if kanji.representation in self._unique_kanji:
            self._unique_kanji[kanji.representation].frequency += 1
            return

        self._unique_kanji[kanji.representation] = kanji

    def add_word(self, word: Word) -&gt; None:
        &#34;&#34;&#34;
        Adds a word to the frequency list.

        If the word is already in the list, then the frequency is increased by 1.
        Otherwise, the word is added to the list with a frequency of 1.

        Note: This method assumes the word is valid.

        Parameters
        ----------
        word : Word
            The word to add.
        &#34;&#34;&#34;
        self._word_count += 1

        if word.representation in self._unique_words.keys():
            self._unique_words[word.representation].add_word(word)
            return

        # if there is no representation of this word then we must add one
        self._unique_words[word.representation] = WordSlot([word])

    def get_representation(self, word: str) -&gt; str:
        &#34;&#34;&#34;
        Returns the representation of a word.
        This is the word without any inflections.
        For example, the representation of &#34;これ&#34; is &#34;此れ&#34;.
        The representation of &#34;行った&#34; is &#34;行く&#34;.
        Parameters
        ----------
        word : str
            The word to get the representation of.
        Returns
        -------
        str
            The representation of the word.
        &#34;&#34;&#34;
        processed_word = self.parse_line(word)[0]

        if len(processed_word) &lt; 1:
            raise ValueError(f&#34;Word &#39;{word}&#39; is not a valid word&#34;)

        return processed_word[0].representation

    def parse_line(self, line: str) -&gt; tuple[list[Word], list[Kanji]]:
        &#34;&#34;&#34;
        Parses a line of text into a list of Words and a list of Kanji.
        Backbone of all parsing.

        Parameters
        ----------
        line : str
            The line to parse.

        Returns
        -------
        tuple[list[Word], list[Kanji]]
            A tuple containing the list of Words and the list of Kanji.
        &#34;&#34;&#34;
        words = self._tagger(line)

        return [Word.from_node(word) for word in words], all_kanji_in_string(line)

    def process_line(self, line_to_process: str) -&gt; None:
        &#34;&#34;&#34;
        Parses a line, adding the valid words and all kanji to the frequency list.
        All other processing functions boil down to this.

        Parameters
        ----------
        line_to_process : str
            The line to process.
        &#34;&#34;&#34;
        line_to_process = line_to_process.replace(&#34;\n&#34;, &#34;&#34;)
        words, kanji = self.parse_line(line_to_process)

        [self.add_kanji(kanji) for kanji in kanji]
        [self.add_word(word) for word in words if self._word_validator(word)]

    def process_text(self, text_to_process: str) -&gt; None:
        &#34;&#34;&#34;
        Parses a string split by the newline character, adding the valid words to the frequency list.

        Parameters
        ----------
        text_to_process : str
            Text potentially containing multiple lines.
        &#34;&#34;&#34;
        [self.process_line(line) for line in text_to_process.split(&#34;\n&#34;)]

    def process_texts(self, texts_to_process: list) -&gt; None:
        &#34;&#34;&#34;
        Parses a list of texts, adding the valid words to the frequency list.

        Parameters
        ----------
        texts_to_process : list
            A list of texts to process.
        &#34;&#34;&#34;
        [self.process_text(text) for text in texts_to_process]

    def process_file(self, file_path: str) -&gt; None:
        &#34;&#34;&#34;
        Parses a file, adding the valid words to the frequency list.
        Parameters
        ----------
        file_path : str
            The path to the file to process.
        &#34;&#34;&#34;
        if not file_exists(file_path):
            raise FileExistsError(
                f&#34;process_file: File path passed doesn&#39;t exist ({file_path})&#34;
            )

        with open(file_path, &#34;r&#34;, encoding=&#34;utf-8&#34;) as fs:
            [self.process_line(line) for line in fs]</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji"><code class="name">var <span class="ident">unique_kanji</span> : int</code></dt>
<dd>
<div class="desc"><p>Returns the number of unique kanji.
Returns</p>
<hr>
<dl>
<dt><code>int</code></dt>
<dd>The number of unique kanji.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def unique_kanji(self) -&gt; int:
    &#34;&#34;&#34;
    Returns the number of unique kanji.
    Returns
    -------
    int
        The number of unique kanji.
    &#34;&#34;&#34;
    return len(self._unique_kanji)</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji_all"><code class="name">var <span class="ident">unique_kanji_all</span> : tuple[int, int, float]</code></dt>
<dd>
<div class="desc"><p>Returns the number of unique kanji, the number of unique kanji used once, and the percentage of unique kanji used once.
Returns</p>
<hr>
<dl>
<dt><code>tuple[int, int, float]</code></dt>
<dd>unique_kanji, unique_kanji_used_once, unique_kanji_used_once_percentage</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def unique_kanji_all(self) -&gt; tuple[int, int, float]:
    &#34;&#34;&#34;
    Returns the number of unique kanji, the number of unique kanji used once, and the percentage of unique kanji used once.
    Returns
    -------
    tuple[int, int, float]
        unique_kanji, unique_kanji_used_once, unique_kanji_used_once_percentage
    &#34;&#34;&#34;
    unique_kanji: int = self.unique_kanji
    unique_kanji_used_once: int = self.unique_kanji_used_once

    unique_kanji_percentage: float = percent_of(
        unique_kanji_used_once, unique_kanji
    )

    return unique_kanji, unique_kanji_used_once, unique_kanji_percentage</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji_used_once"><code class="name">var <span class="ident">unique_kanji_used_once</span> : int</code></dt>
<dd>
<div class="desc"><p>Returns the number of unique kanji used once.
Returns</p>
<hr>
<dl>
<dt><code>int</code></dt>
<dd>The number of unique kanji used once.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def unique_kanji_used_once(self) -&gt; int:
    &#34;&#34;&#34;
    Returns the number of unique kanji used once.
    Returns
    -------
    int
        The number of unique kanji used once.
    &#34;&#34;&#34;
    return len(
        [kanji for kanji in self._unique_kanji.values() if kanji.frequency == 1]
    )</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words"><code class="name">var <span class="ident">unique_words</span> : int</code></dt>
<dd>
<div class="desc"><p>Returns the number of unique words.
Returns</p>
<hr>
<dl>
<dt><code>int</code></dt>
<dd>The number of unique words.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def unique_words(self) -&gt; int:
    &#34;&#34;&#34;
    Returns the number of unique words.
    Returns
    -------
    int
        The number of unique words.
    &#34;&#34;&#34;
    return len(self.wordslots)</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words_all"><code class="name">var <span class="ident">unique_words_all</span> : tuple[int, int, float]</code></dt>
<dd>
<div class="desc"><p>Returns the number of unique words, the number of unique words used once, and the percentage of unique words used once.
Returns</p>
<hr>
<dl>
<dt><code>tuple[int, int, float]</code></dt>
<dd>unique_words, unique_words_used_once, unique_words_used_once_percentage</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def unique_words_all(self) -&gt; tuple[int, int, float]:
    &#34;&#34;&#34;
    Returns the number of unique words, the number of unique words used once, and the percentage of unique words used once.
    Returns
    -------
    tuple[int, int, float]
        unique_words, unique_words_used_once, unique_words_used_once_percentage
    &#34;&#34;&#34;
    unique_words: int = self.unique_words
    unique_words_used_once: int = self.unique_words_used_once

    unique_word_percentage: float = percent_of(unique_words_used_once, unique_words)

    return unique_words, unique_words_used_once, unique_word_percentage</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words_used_once"><code class="name">var <span class="ident">unique_words_used_once</span> : int</code></dt>
<dd>
<div class="desc"><p>Returns the number of unique words used once.
Returns</p>
<hr>
<dl>
<dt><code>int</code></dt>
<dd>The number of unique words used once.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def unique_words_used_once(self) -&gt; int:
    &#34;&#34;&#34;
    Returns the number of unique words used once.
    Returns
    -------
    int
        The number of unique words used once.
    &#34;&#34;&#34;
    return len(get_unique_wordslots(self.wordslots))</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.word_count"><code class="name">var <span class="ident">word_count</span> : int</code></dt>
<dd>
<div class="desc"><p>Returns the number of words.
Returns</p>
<hr>
<dl>
<dt><code>int</code></dt>
<dd>The number of words.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def word_count(self) -&gt; int:
    &#34;&#34;&#34;
    Returns the number of words.
    Returns
    -------
    int
        The number of words.
    &#34;&#34;&#34;
    return self._word_count</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.wordslots"><code class="name">var <span class="ident">wordslots</span> : list[<a title="jpfreq.word_slot.WordSlot" href="word_slot.html#jpfreq.word_slot.WordSlot">WordSlot</a>]</code></dt>
<dd>
<div class="desc"><p>Returns a list of all the wordslots.
Returns</p>
<hr>
<dl>
<dt><code>list[WordSlot]</code></dt>
<dd>A list of all the wordslots.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def wordslots(self) -&gt; list[WordSlot]:
    &#34;&#34;&#34;
    Returns a list of all the wordslots.
    Returns
    -------
    list[WordSlot]
        A list of all the wordslots.
    &#34;&#34;&#34;
    return list(self._unique_words.values())</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.add_kanji"><code class="name flex">
<span>def <span class="ident">add_kanji</span></span>(<span>self, kanji: <a title="jpfreq.kanji.Kanji" href="kanji.html#jpfreq.kanji.Kanji">Kanji</a>) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a kanji to the frequency list.
Parameters</p>
<hr>
<dl>
<dt><strong><code>kanji</code></strong> :&ensp;<code>Kanji</code></dt>
<dd>The kanji to add.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_kanji(self, kanji: Kanji) -&gt; None:
    &#34;&#34;&#34;
    Adds a kanji to the frequency list.
    Parameters
    ----------
    kanji : Kanji
        The kanji to add.
    &#34;&#34;&#34;
    if kanji.representation in self._unique_kanji:
        self._unique_kanji[kanji.representation].frequency += 1
        return

    self._unique_kanji[kanji.representation] = kanji</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.add_word"><code class="name flex">
<span>def <span class="ident">add_word</span></span>(<span>self, word: <a title="jpfreq.word.Word" href="word.html#jpfreq.word.Word">Word</a>) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Adds a word to the frequency list.</p>
<p>If the word is already in the list, then the frequency is increased by 1.
Otherwise, the word is added to the list with a frequency of 1.</p>
<p>Note: This method assumes the word is valid.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>word</code></strong> :&ensp;<code>Word</code></dt>
<dd>The word to add.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_word(self, word: Word) -&gt; None:
    &#34;&#34;&#34;
    Adds a word to the frequency list.

    If the word is already in the list, then the frequency is increased by 1.
    Otherwise, the word is added to the list with a frequency of 1.

    Note: This method assumes the word is valid.

    Parameters
    ----------
    word : Word
        The word to add.
    &#34;&#34;&#34;
    self._word_count += 1

    if word.representation in self._unique_words.keys():
        self._unique_words[word.representation].add_word(word)
        return

    # if there is no representation of this word then we must add one
    self._unique_words[word.representation] = WordSlot([word])</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Clears the frequency list of all words and kanji, reverting it to its initial state.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear(self) -&gt; None:
    &#34;&#34;&#34;
    Clears the frequency list of all words and kanji, reverting it to its initial state.
    &#34;&#34;&#34;
    self._word_count = 0

    self._unique_words.clear()
    self._unique_kanji.clear()</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.generate_text_info"><code class="name flex">
<span>def <span class="ident">generate_text_info</span></span>(<span>self) ‑> <a title="jpfreq.text_info.TextInfo" href="text_info.html#jpfreq.text_info.TextInfo">TextInfo</a></span>
</code></dt>
<dd>
<div class="desc"><p>Generates a TextInfo object from the frequency list.
Returns</p>
<hr>
<dl>
<dt><code>TextInfo</code></dt>
<dd>A TextInfo object containing information about the text.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_text_info(self) -&gt; TextInfo:
    &#34;&#34;&#34;
    Generates a TextInfo object from the frequency list.
    Returns
    -------
    TextInfo
        A TextInfo object containing information about the text.
    &#34;&#34;&#34;
    (
        unique_words,
        unique_words_used_once,
        unique_word_percentage,
    ) = self.unique_words_all
    (
        unique_kanji,
        unique_kanji_used_once,
        unique_kanji_percentage,
    ) = self.unique_kanji_all

    return TextInfo(
        self.word_count,
        unique_words,
        unique_words_used_once,
        unique_word_percentage,
        unique_kanji,
        unique_kanji_used_once,
        unique_kanji_percentage,
    )</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.get_most_frequent"><code class="name flex">
<span>def <span class="ident">get_most_frequent</span></span>(<span>self, limit: int = 100) ‑> list[<a title="jpfreq.word_slot.WordSlot" href="word_slot.html#jpfreq.word_slot.WordSlot">WordSlot</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of the most frequent words in the text with the specified limit.
If limit is -1, then all words are returned.
Parameters</p>
<hr>
<dl>
<dt><strong><code>limit</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of words to return.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list[WordSlot]</code></dt>
<dd>A list of the most frequent words in the text with the specified limit, sorted by frequency.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_most_frequent(self, limit: int = 100) -&gt; list[WordSlot]:
    &#34;&#34;&#34;
    Returns a list of the most frequent words in the text with the specified limit.
    If limit is -1, then all words are returned.
    Parameters
    ----------
    limit : int
        The number of words to return.
    Returns
    -------
    list[WordSlot]
        A list of the most frequent words in the text with the specified limit, sorted by frequency.
    &#34;&#34;&#34;
    item_array: list[WordSlot] = sorted(
        self.wordslots, key=lambda x: x.frequency, reverse=True
    )

    if limit == -1 or limit &gt; len(item_array):
        return item_array

    return item_array[:limit]</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.get_representation"><code class="name flex">
<span>def <span class="ident">get_representation</span></span>(<span>self, word: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the representation of a word.
This is the word without any inflections.
For example, the representation of "これ" is "此れ".
The representation of "行った" is "行く".
Parameters</p>
<hr>
<dl>
<dt><strong><code>word</code></strong> :&ensp;<code>str</code></dt>
<dd>The word to get the representation of.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The representation of the word.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_representation(self, word: str) -&gt; str:
    &#34;&#34;&#34;
    Returns the representation of a word.
    This is the word without any inflections.
    For example, the representation of &#34;これ&#34; is &#34;此れ&#34;.
    The representation of &#34;行った&#34; is &#34;行く&#34;.
    Parameters
    ----------
    word : str
        The word to get the representation of.
    Returns
    -------
    str
        The representation of the word.
    &#34;&#34;&#34;
    processed_word = self.parse_line(word)[0]

    if len(processed_word) &lt; 1:
        raise ValueError(f&#34;Word &#39;{word}&#39; is not a valid word&#34;)

    return processed_word[0].representation</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.parse_line"><code class="name flex">
<span>def <span class="ident">parse_line</span></span>(<span>self, line: str) ‑> tuple[list[<a title="jpfreq.word.Word" href="word.html#jpfreq.word.Word">Word</a>], list[<a title="jpfreq.kanji.Kanji" href="kanji.html#jpfreq.kanji.Kanji">Kanji</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Parses a line of text into a list of Words and a list of Kanji.
Backbone of all parsing.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>line</code></strong> :&ensp;<code>str</code></dt>
<dd>The line to parse.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple[list[Word], list[Kanji]]</code></dt>
<dd>A tuple containing the list of Words and the list of Kanji.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_line(self, line: str) -&gt; tuple[list[Word], list[Kanji]]:
    &#34;&#34;&#34;
    Parses a line of text into a list of Words and a list of Kanji.
    Backbone of all parsing.

    Parameters
    ----------
    line : str
        The line to parse.

    Returns
    -------
    tuple[list[Word], list[Kanji]]
        A tuple containing the list of Words and the list of Kanji.
    &#34;&#34;&#34;
    words = self._tagger(line)

    return [Word.from_node(word) for word in words], all_kanji_in_string(line)</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.process_file"><code class="name flex">
<span>def <span class="ident">process_file</span></span>(<span>self, file_path: str) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Parses a file, adding the valid words to the frequency list.
Parameters</p>
<hr>
<dl>
<dt><strong><code>file_path</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the file to process.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_file(self, file_path: str) -&gt; None:
    &#34;&#34;&#34;
    Parses a file, adding the valid words to the frequency list.
    Parameters
    ----------
    file_path : str
        The path to the file to process.
    &#34;&#34;&#34;
    if not file_exists(file_path):
        raise FileExistsError(
            f&#34;process_file: File path passed doesn&#39;t exist ({file_path})&#34;
        )

    with open(file_path, &#34;r&#34;, encoding=&#34;utf-8&#34;) as fs:
        [self.process_line(line) for line in fs]</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.process_line"><code class="name flex">
<span>def <span class="ident">process_line</span></span>(<span>self, line_to_process: str) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Parses a line, adding the valid words and all kanji to the frequency list.
All other processing functions boil down to this.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>line_to_process</code></strong> :&ensp;<code>str</code></dt>
<dd>The line to process.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_line(self, line_to_process: str) -&gt; None:
    &#34;&#34;&#34;
    Parses a line, adding the valid words and all kanji to the frequency list.
    All other processing functions boil down to this.

    Parameters
    ----------
    line_to_process : str
        The line to process.
    &#34;&#34;&#34;
    line_to_process = line_to_process.replace(&#34;\n&#34;, &#34;&#34;)
    words, kanji = self.parse_line(line_to_process)

    [self.add_kanji(kanji) for kanji in kanji]
    [self.add_word(word) for word in words if self._word_validator(word)]</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.process_text"><code class="name flex">
<span>def <span class="ident">process_text</span></span>(<span>self, text_to_process: str) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Parses a string split by the newline character, adding the valid words to the frequency list.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>text_to_process</code></strong> :&ensp;<code>str</code></dt>
<dd>Text potentially containing multiple lines.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_text(self, text_to_process: str) -&gt; None:
    &#34;&#34;&#34;
    Parses a string split by the newline character, adding the valid words to the frequency list.

    Parameters
    ----------
    text_to_process : str
        Text potentially containing multiple lines.
    &#34;&#34;&#34;
    [self.process_line(line) for line in text_to_process.split(&#34;\n&#34;)]</code></pre>
</details>
</dd>
<dt id="jpfreq.jp_frequency_list.JapaneseFrequencyList.process_texts"><code class="name flex">
<span>def <span class="ident">process_texts</span></span>(<span>self, texts_to_process: list) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Parses a list of texts, adding the valid words to the frequency list.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>texts_to_process</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of texts to process.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_texts(self, texts_to_process: list) -&gt; None:
    &#34;&#34;&#34;
    Parses a list of texts, adding the valid words to the frequency list.

    Parameters
    ----------
    texts_to_process : list
        A list of texts to process.
    &#34;&#34;&#34;
    [self.process_text(text) for text in texts_to_process]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#japanese-frequency-list">Japanese Frequency List</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="jpfreq" href="index.html">jpfreq</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="jpfreq.jp_frequency_list.word_validator_exclude_by_type" href="#jpfreq.jp_frequency_list.word_validator_exclude_by_type">word_validator_exclude_by_type</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList">JapaneseFrequencyList</a></code></h4>
<ul class="">
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.add_kanji" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.add_kanji">add_kanji</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.add_word" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.add_word">add_word</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.clear" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.clear">clear</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.generate_text_info" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.generate_text_info">generate_text_info</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.get_most_frequent" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.get_most_frequent">get_most_frequent</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.get_representation" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.get_representation">get_representation</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.parse_line" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.parse_line">parse_line</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.process_file" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.process_file">process_file</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.process_line" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.process_line">process_line</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.process_text" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.process_text">process_text</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.process_texts" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.process_texts">process_texts</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji">unique_kanji</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji_all" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji_all">unique_kanji_all</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji_used_once" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_kanji_used_once">unique_kanji_used_once</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words">unique_words</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words_all" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words_all">unique_words_all</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words_used_once" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.unique_words_used_once">unique_words_used_once</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.word_count" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.word_count">word_count</a></code></li>
<li><code><a title="jpfreq.jp_frequency_list.JapaneseFrequencyList.wordslots" href="#jpfreq.jp_frequency_list.JapaneseFrequencyList.wordslots">wordslots</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>